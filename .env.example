# AI Nexus Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# API Keys (Optional - fallback to Free Web (g4f) if not provided)
# =============================================================================
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=
PERPLEXITY_API_KEY=

# =============================================================================
# Network Configuration
# =============================================================================
# Ollama Configuration (for local LLM models)
OLLAMA_HOST=localhost
OLLAMA_PORT=11434

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Streamlit App Configuration  
STREAMLIT_HOST=0.0.0.0
STREAMLIT_PORT=8501

# =============================================================================
# Paths (use absolute paths or relative to project root)
# =============================================================================
MEMORY_DB_PATH=./memory_db
HAR_COOKIES_PATH=./har_and_cookies
CUSTOM_PROVIDERS_FILE=./custom_providers.json

# =============================================================================
# Timeouts (in seconds)
# =============================================================================
API_TIMEOUT=30.0
OLLAMA_TIMEOUT=60.0

# =============================================================================
# Feature Flags
# =============================================================================
ENABLE_MEMORY=true
ENABLE_G4F=true

# =============================================================================
# Remote Ollama Setup (for network/cluster usage)
# =============================================================================
# To use a remote Ollama instance, set:
# OLLAMA_HOST=192.168.1.100  # Your Ollama server IP
# OLLAMA_PORT=11434

# =============================================================================
# Docker/Cloud Deployment
# =============================================================================
# For cloud deployment, you might want:
# API_HOST=0.0.0.0  # Allow external connections
# OLLAMA_HOST=ollama-service  # Docker service name or external IP
